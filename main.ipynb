{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Language Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yUu7uWcVJHNu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import regex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
        "from tensorflow_text.tools.wordpiece_vocab.bert_vocab_from_dataset import bert_vocab_from_dataset\n",
        "from tensorflow_text import BertTokenizer\n",
        "from tensorflow_text import pad_model_inputs\n",
        "from tensorflow_text import sliding_window"
      ],
      "metadata": {
        "id": "8mHQSdYutULs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Pride and Prejudice, 1342\n",
        "Adventures in Wonderland, 11\n",
        "Adventures of Sherlock Holmes, 1661\n",
        "Frankenstein, 84\n",
        "Moby Dick, 2701\n",
        "Dracula, 345\n",
        "Ulysses, 4300\n",
        "The Picture of Dorian Gray, 174\n",
        "A Tale of Two Cities, 98\n",
        "The Great Gatsby, 64317\n",
        "Great Expectations, 1400\n",
        "Crime and Punishment, 2554\n",
        "Metamorphosis, 5200\n",
        "Iliad, 6130\n",
        "The Prince, 1232\n",
        "Heart of Darkness, 219\n",
        "Les Misérables, 135\n",
        "'''\n",
        "\n",
        "def get_text(text_id):\n",
        "    text_id = str(text_id)\n",
        "    url = f'https://www.gutenberg.org/files/{text_id}/{text_id}-h/{text_id}-h.htm'\n",
        "    text = requests.get(url).content.decode('utf-8')\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    text = [p.get_text() for p in soup.find_all('p')]\n",
        "    text = ' '.join(text)\n",
        "    for comma in \"\\\"‘’‚‛“„‟\":\n",
        "        text = text.replace(comma, \"'\")\n",
        "    text = ' '.join(text.split())\n",
        "    text = ''.join(regex.findall(\"[A-Za-z .,()!?']\", text))\n",
        "    return text\n",
        "\n",
        "# Training on Great Expectations, Crime and Punishment and Les Misérables\n",
        "# All texts from the 1860s\n",
        "texts = [get_text(i) for i in [1400, 2554, 135]]"
      ],
      "metadata": {
        "id": "8FQ3K4iiBW3e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 512\n",
        "\n",
        "bert_vocab_args = dict(vocab_size = vocab_size,\n",
        "                    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"],\n",
        "                    bert_tokenizer_params={'lower_case':False},\n",
        "                    learn_params={})\n",
        "data = tf.data.Dataset.from_tensor_slices(texts)\n",
        "vocab = bert_vocab_from_dataset(data, **bert_vocab_args)\n",
        "\n",
        "with open('vocab.txt', 'w') as f:\n",
        "    for token in vocab:\n",
        "        f.write(token + '\\n')\n",
        "\n",
        "tokenizer = BertTokenizer('vocab.txt', lower_case = False)"
      ],
      "metadata": {
        "id": "RaF4nUPT0bdA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(prompts):\n",
        "    return tokenizer.tokenize(prompts).merge_dims(1, 2)\n",
        "\n",
        "def decode(tokens):\n",
        "    out = []\n",
        "    for t in tokens:\n",
        "        out.append(tf.strings.join(tokenizer.detokenize([t])[0], ' ').numpy().decode('utf8'))\n",
        "    return out"
      ],
      "metadata": {
        "id": "Yi15BmhkzHvd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 128\n",
        "tokenized_texts = encode(texts)"
      ],
      "metadata": {
        "id": "v_xgB9Is9yIg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = tf.concat([sliding_window(text, seq_len + 1) for text in tokenized_texts], axis=0)"
      ],
      "metadata": {
        "id": "gIiO6Ic7KuF9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = tf.random.shuffle(prompts)\n",
        "split = int(prompts.shape[0]*0.8)\n",
        "x_train, y_train = prompts[:split][:,:-1], prompts[:split][:,-1]\n",
        "x_test, y_test = prompts[split:][:,:-1], prompts[split:][:,-1]"
      ],
      "metadata": {
        "id": "7BQaiNuS-wqY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw-HivLFgiMo",
        "outputId": "9c87233e-a61d-41fb-b028-b59429461d3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1755128, 128) (438783, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# From Tensorflow Guide\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "WRi8IRebvtZK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim):\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6, axis = -1)(inputs)\n",
        "\n",
        "    y = inputs + tf.keras.layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads)(x, x)\n",
        "    y = tf.keras.layers.LayerNormalization(epsilon=1e-6, axis = -1)(y)\n",
        "\n",
        "    y = tf.keras.layers.Dense(ff_dim, activation='relu')(y)\n",
        "    y = tf.keras.layers.Dense(inputs.shape[-1])(y)\n",
        "    \n",
        "    return inputs + y\n",
        "\n",
        "def build_model(input_shape, layers, num_heads, head_size, ff_dim):\n",
        "    \n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    x = tf.keras.layers.Embedding(vocab_size, num_heads*head_size, input_length=seq_len)(x)\n",
        "    x *= tf.math.sqrt(tf.cast(num_heads*head_size, tf.float32))\n",
        "    x += positional_encoding(seq_len, num_heads*head_size)[:, :seq_len, :]\n",
        "\n",
        "    for _ in range(layers):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
        "    outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(x)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "aabStFqf2HQo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(input_shape=(seq_len,),\n",
        "                    layers=4, num_heads=4,\n",
        "                    head_size=16, ff_dim=256)"
      ],
      "metadata": {
        "id": "FjBakJF9LBxc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "W1-CpYp9LUy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0208e1-36c4-4c77-da28-e547cc0155ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 128, 64)      32768       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 128, 64)      0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 128, 64)     0           ['tf.math.multiply[0][0]']       \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 128, 64)     128         ['tf.__operators__.add[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 128, 64)     16640       ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add[0][0]',   \n",
            " mbda)                                                            'multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 128, 64)     128         ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128, 256)     16640       ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128, 64)      16448       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add[0][0]',   \n",
            " mbda)                                                            'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 128, 64)     128         ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 128, 64)     16640       ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add_2[0][0]', \n",
            " mbda)                                                            'multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 128, 64)     128         ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128, 256)     16640       ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128, 64)      16448       ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add_2[0][0]', \n",
            " mbda)                                                            'dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 128, 64)     128         ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 128, 64)     16640       ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add_4[0][0]', \n",
            " mbda)                                                            'multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 128, 64)     128         ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128, 256)     16640       ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 128, 64)      16448       ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add_4[0][0]', \n",
            " mbda)                                                            'dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 128, 64)     128         ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 128, 64)     16640       ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add_6[0][0]', \n",
            " mbda)                                                            'multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 128, 64)     128         ['tf.__operators__.add_7[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128, 256)     16640       ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 128, 64)      16448       ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  (None, 128, 64)     0           ['tf.__operators__.add_6[0][0]', \n",
            " mbda)                                                            'dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['tf.__operators__.add_8[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 256)          16640       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 512)          131584      ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 380,928\n",
            "Trainable params: 380,928\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# From Tensorflow Guide\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = CustomSchedule(64)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "KAnwWKG_9RcO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer=optimizer, loss=scce, metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "JgoN4AqtMwUM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR37HVuyP7F6",
        "outputId": "dcf92c2e-b9e9-4445-b07a-97005e519f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6856/6856 [==============================] - 581s 84ms/step - loss: 4.1957 - sparse_categorical_accuracy: 0.1376\n",
            "Epoch 2/10\n",
            "5774/6856 [========================>.....] - ETA: 1:31 - loss: 3.4441 - sparse_categorical_accuracy: 0.2302"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "id": "qWAjskTLrtJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "h0pL7NINZ6Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regress(inputs, n):\n",
        "    x = inputs\n",
        "\n",
        "    for _ in range(n):\n",
        "        y = tf.reshape(tf.math.argmax(model(x[:,-seq_len:]), axis=-1), (-1, 1))\n",
        "        x = tf.concat((x, y), axis=1)\n",
        "    \n",
        "    for i in range(len(inputs)):\n",
        "        print(decode(inputs[i:i+1])[0] + ' (begin new text) ' + decode(x[i:i+1][:,seq_len:])[0])\n",
        "        print('')"
      ],
      "metadata": {
        "id": "D4_qmpDeann_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regress(x_test[:10], 30)"
      ],
      "metadata": {
        "id": "GiBbVOPiaS61"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
